import comp from "E:/Myown/Blog/.temp/pages/dl/cv/CV.html.vue"
const data = JSON.parse("{\"path\":\"/dl/cv/CV.html\",\"title\":\"常见卷积神经网络\",\"lang\":\"zh-CN\",\"frontmatter\":{\"title\":\"常见卷积神经网络\",\"author\":\"xbZhong\",\"isOriginal\":true,\"article\":true,\"category\":\"cv\",\"timeline\":true,\"icon\":\"line-md:computer-twotone\",\"date\":\"2025-07-01T00:00:00.000Z\",\"description\":\"本页PDF Alexnet 多个CNN层堆叠而成的经典卷积神经网络，用于图像分类的任务 使用了ReLU激活函数，防止深层次的网络导致梯度消失 使用Dropout正则化，解决过拟合问题 使用池化层进行进行降维 GoogleNet 传统CNN通多堆叠卷积层可以学习到图像更多特征，但会导致 计算量爆炸 梯度消失 过拟合 Googlenet设计了宽而深的结构，...\",\"head\":[[\"script\",{\"type\":\"application/ld+json\"},\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Article\\\",\\\"headline\\\":\\\"常见卷积神经网络\\\",\\\"image\\\":[\\\"https://xbzhong.cn/screenshot/dl/image-20250804105749792.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250804105823459.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250804110823817.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250804145938060.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250804154119715.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250805173724557.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250805182841345.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250806173546405.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250804103117355.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250806105614387.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250809155500175.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250809162635744.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250805103319336.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250805110113933.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250807104036319.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250807104102110.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250807113641978.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250808100134981.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250811180354848.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250811173140965.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250811175302080.png\\\",\\\"https://xbzhong.cn/screenshot/dl/image-20250811175327478.png\\\"],\\\"datePublished\\\":\\\"2025-07-01T00:00:00.000Z\\\",\\\"dateModified\\\":null,\\\"author\\\":[{\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"xbZhong\\\"}]}\"],[\"meta\",{\"property\":\"og:url\",\"content\":\"https://xbzhong.cn/dl/cv/CV.html\"}],[\"meta\",{\"property\":\"og:site_name\",\"content\":\"阿b的博客\"}],[\"meta\",{\"property\":\"og:title\",\"content\":\"常见卷积神经网络\"}],[\"meta\",{\"property\":\"og:description\",\"content\":\"本页PDF Alexnet 多个CNN层堆叠而成的经典卷积神经网络，用于图像分类的任务 使用了ReLU激活函数，防止深层次的网络导致梯度消失 使用Dropout正则化，解决过拟合问题 使用池化层进行进行降维 GoogleNet 传统CNN通多堆叠卷积层可以学习到图像更多特征，但会导致 计算量爆炸 梯度消失 过拟合 Googlenet设计了宽而深的结构，...\"}],[\"meta\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"meta\",{\"property\":\"og:image\",\"content\":\"https://xbzhong.cn/screenshot/dl/image-20250804105749792.png\"}],[\"meta\",{\"property\":\"og:locale\",\"content\":\"zh-CN\"}],[\"meta\",{\"property\":\"article:author\",\"content\":\"xbZhong\"}],[\"meta\",{\"property\":\"article:published_time\",\"content\":\"2025-07-01T00:00:00.000Z\"}]]},\"readingTime\":{\"minutes\":24.27,\"words\":7280},\"filePathRelative\":\"dl/cv/CV.md\",\"excerpt\":\"<p><a href=\\\"/pdfs/dl/cv/CV.pdf\\\">本页PDF</a></p>\\n<h2>Alexnet</h2>\\n<p>多个CNN层堆叠而成的经典卷积神经网络，用于图像分类的任务</p>\\n<ul>\\n<li>使用了ReLU激活函数，防止深层次的网络导致<strong>梯度消失</strong></li>\\n<li>使用Dropout正则化，解决<strong>过拟合问题</strong></li>\\n<li>使用池化层进行进行<strong>降维</strong></li>\\n</ul>\\n<h2>GoogleNet</h2>\\n<p>传统CNN通多堆叠卷积层可以学习到图像更多特征，但会导致</p>\",\"autoDesc\":true}")
export { comp, data }

if (import.meta.webpackHot) {
  import.meta.webpackHot.accept()
  if (__VUE_HMR_RUNTIME__.updatePageData) {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  }
}

if (import.meta.hot) {
  import.meta.hot.accept(({ data }) => {
    __VUE_HMR_RUNTIME__.updatePageData(data)
  })
}
