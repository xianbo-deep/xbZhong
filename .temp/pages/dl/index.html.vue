<template><div><h2 id="写在前面" tabindex="-1"><a class="header-anchor" href="#写在前面"><span>写在前面</span></a></h2>
<p>大一暑假开始我开始接触这方面知识，不过那时候并未系统学习机器学习，属于有点<strong>囫囵吞枣</strong>。</p>
<ul>
<li>我先是从吴恩达的老师的机器学习入门课程开始，b站上就有，然后写下了<RouteLink to="/dl/primer/ML.html">第一篇笔记</RouteLink></li>
<li>然后学习小土堆的pytorch视频，写下了<RouteLink to="/dl/pytorch/pytorch.html">第一篇pytorch笔记</RouteLink></li>
<li>接着学习李沐老师的动手学深度学习</li>
<li>接着作罢，没再学习下去，因为开学了，卷绩点了</li>
</ul>
<p>断断续续接触了LLM、CV，开始有了初步认识，从我叔那里得知生成式模型，不知天高地厚开啃<RouteLink to="/dl/cv/VAE.html">VAE</RouteLink>和<RouteLink to="/dl/cv/DiffusionModel.html">扩散模型</RouteLink>，太特么难了，没啃完</p>
<p>大一暑假开始做大创，老师给的课题方向是LLM和知识图谱，按要求做了APP，和这方向不沾边，后面越走越偏，学不到东西，作罢</p>
<p>大二暑假前看了李宏毅老师22年的课程，做了<RouteLink to="/dl/primer/DL.html">笔记</RouteLink></p>
<p>大二暑假去了个小厂实习，算是对这方面有了见解，自己用之前学的知识用FastAPI搭了个接口，然后胡塞一堆中间件，Redis，Celery，把微调好的模型用VLLM一塞，也不知道后面落地能不能用上，九月份做完就离职了</p>
<ul>
<li>在这期间系统性学了<RouteLink to="/dl/llm/LLM.html">LLM</RouteLink>，还有一些分布式训练知识，注意力机制变体等，学会了手写MHA</li>
<li>无聊的时候复现了一些卷积神经网络，跟着b站视频读了些文献</li>
</ul>
<p>我还是蛮想搞算法的，奈何没资源，学历也不够好，也不知道研究生去哪里读，目前这方面学习也停滞了，打算读研再继续吧</p>
</div></template>


