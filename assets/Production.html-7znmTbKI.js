import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,e as i,o as d}from"./app-W11mDvk5.js";const s={};function l(n,t){return d(),o("div",null,[...t[0]||(t[0]=[i(`<p><strong>阿里云镜像</strong>：<code>-i https://mirrors.aliyun.com/pypi/simple/</code></p><p><code>nvidia-smi</code>：针对N卡，查看GPU型号，显存使用情况，使用率等</p><p><code>lscpu</code>：查看cpu的信息</p><ul><li><code>P-core</code>：性能核心（支持超线程，可以虚拟化为2个核心）</li><li><code>E-core</code>：能效核心（不支持超线程）</li></ul><p><code>lscpu | grep cache </code> ： 显示各级缓存大小</p><p><code>ls</code>：查看当前目录下信息</p><p><code>conda env list</code>：查看已建立的虚拟环境</p><p><code>conda deactivate</code>：退出当前环境</p><p><code>pwd</code>：查看当前路径</p><p><code>conda create -n videollava python = 3.10 -y</code>：建立一个名为videollava的虚拟环境</p><p><code>mv oldname newname</code>：给文件夹命名</p><p><code>conda remove --name myenv --all</code>：删除名字为myenv的虚拟环境</p><p><code>rm -rf your_folder_name</code>：删除文件夹</p><p><code>conda search qwen-vl-utils -c conda-forge</code>：search为寻找，后面跟着包名，<code>-c conda-forge</code>为社区频道</p><p><code>conda install -c conda-forge qwen-vl-utils=0.0.11 -y</code>：<code> -y</code>为直接同意</p><p><code>uptime</code>：查看系统运行时间</p><p><code>uptime -s</code>：查看上次运行时间</p><p><code>top</code>：实时监控CPU和内存使用</p><ul><li>按1：监控CPU运行情况 <ul><li>us：用户态占用</li><li>sy：系统态占用</li><li>id：空闲率</li></ul></li></ul><p><code>history</code>：查看历史命令</p><p><code>df -h</code>：查看磁盘空间使用情况，硬盘是永久存储的，但读取速度很慢</p><ul><li><code>tmfps</code>：临时文件系统，数据存在RAM（内存）中</li><li><code>/dev/nvme0n1p2</code>：主系统分区</li><li><code>/dev/nvme0n1p1</code>：存储系统启动文件</li><li><code>efivarfs</code>：虚拟文件系统</li></ul><p><code>free -h</code>：查看内存使用情况，内存是临时存储的，断电后会丢失，读取速度极快</p><ul><li><code>total</code>：总内存</li><li><code>used</code>：已用内存（包括缓存和缓冲区）</li><li><code>free</code>：完全空闲的内存</li><li><code>buff/cache</code>：被内核缓存和缓冲区占用的内存</li><li><code>available</code>：实际可用的内存</li></ul><p><code>nvcc --verison</code>：查看cuda版本</p><p><code>tensorboard --logdir=./logs --port=6006 --bind_all</code></p><ul><li><code>--logdir</code>: 指向你的日志目录（和 <code>logging_dir</code> 一致）</li><li><code>--port</code>: 指定端口（默认6006）</li><li><code>--bind_all</code>: 允许外部访问</li></ul><p><code>ps aux</code>：查看进程</p><ul><li><code>ps</code>：Process Status（进程状态）</li><li><code>a</code>：显示所有用户的进程（而不仅是当前用户）</li><li><code>u</code>：以用户为导向的格式（显示详细信息）</li><li><code>x</code>：包括未关联终端的进程（如后台服务）</li></ul><p><code>kill -9 1234</code>：强制杀死PID为1234的进程</p><p><code>ssh -L [本地端口]:[远程主机]:[远程端口] [用户名]@[服务器地址]</code>：将远程服务器端口转发至本地端口</p><p><strong>防火墙相关</strong></p><p><code>sudo ufw status</code>：用管理员权限查看防火墙状态</p><p><code>sudo ufw allow/deny 8080</code>：开放/拒绝8080端口</p><p><code>sudo ufw enable/disable</code>：启用/禁用防火墙</p><p><strong>系统服务相关</strong></p><p><code>sudo systemctl status nginx</code>：查看服务状态</p><p><code>sudo systemctl start/stop/restart redis</code>：启动/停止/重启服务</p><p><code>sudo systemctl enable/disable redis</code>：启动/取消开机自启</p><p><code>tops</code>：衡量处理器基本运算操作的次数，单位为<strong>万亿次/秒</strong></p><p><strong>对比单位</strong>：</p><ul><li>1 GOPS = 10亿次/秒</li><li>1 POPS = 1000万亿次/秒</li></ul><h5 id="模型参数" tabindex="-1"><a class="header-anchor" href="#模型参数"><span><strong>模型参数</strong></span></a></h5><p><strong>精度</strong></p><table><thead><tr><th>名称</th><th>参数</th><th>位数</th><th>适用范围</th></tr></thead><tbody><tr><td>全精度(FP32)</td><td>torch.float32</td><td>32</td><td>训练，高精度推理</td></tr><tr><td>半精度(FP16)</td><td>torch.float16</td><td>16</td><td>推理</td></tr><tr><td>脑浮点(BF16)</td><td>torch.bfloat16</td><td>16</td><td>Ampere架构GPU训练</td></tr><tr><td>TF(32)</td><td>自动启用(为FP32)</td><td>19</td><td>NVIDIA Ampere架构的矩阵运算加速</td></tr><tr><td>INT8</td><td><strong>1字节/参数</strong>（FP32的1/4）</td><td>8-bit整数</td><td>边缘设备部署</td></tr><tr><td>INT4</td><td><strong>0.5字节/参数</strong>（FP32的1/8)</td><td>4-bit整数</td><td>边缘设备部署</td></tr></tbody></table><p><strong>变体</strong></p><p>模型权重的存储格式或优化版本，与精度绑定</p><table><thead><tr><th>名称</th><th>说明</th><th>关联精度</th></tr></thead><tbody><tr><td>fp32</td><td>全精度权重</td><td>torch.float32</td></tr><tr><td>fp16</td><td>半精度权重</td><td>torch.float16</td></tr><tr><td>bf16</td><td>脑浮点权重</td><td>torch.bfloat16</td></tr><tr><td>tf32</td><td>计算时使用(为FP32)</td><td>自动启用</td></tr></tbody></table><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"> # 8-bit量化配置</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        quant_config </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> BitsAndBytesConfig</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            load_in_8bit</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">True</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">            bnb_4bit_compute_dtype</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">torch.bfloat16</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        )</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>计算的时候反量化为bfloat16，存储的时候还是INT8-bit</p><h5 id="cuda" tabindex="-1"><a class="header-anchor" href="#cuda"><span>CUDA</span></a></h5><p><strong>硬件层面</strong></p><ul><li><strong>CUDA Core</strong>：GPU 的基本计算单元，每个核心可执行一个线程的运算</li><li><strong>SM（Streaming Multiprocessor）</strong>： <ul><li>GPU 的计算单元，每个 SM 包含多个 CUDA Core、共享内存、寄存器等。</li></ul></li></ul><p><strong>内存层次</strong></p><ul><li><strong>全局内存（Global Memory）</strong>：所有线程可访问，带宽高但延迟高（类似 CPU 的 RAM）。</li><li><strong>共享内存（Shared Memory）</strong>：SM 内线程共享，低延迟（类似 CPU 缓存）。</li><li><strong>寄存器（Registers）</strong>：每个线程私有，速度最快。</li></ul><p><strong>软件层面</strong></p><ul><li><strong>Kernel</strong>（内核函数） <ul><li>在GPU上并行执行的函数</li></ul></li><li><strong>线程层次</strong><ul><li><strong>Thread</strong>：最小执行单元</li><li><strong>Block</strong>：一组线程，共享同一SM的资源</li><li><strong>Grid</strong>：多个Block的集合，构成一个完整的Kernel任务</li></ul></li></ul><h5 id="cuda核心组件" tabindex="-1"><a class="header-anchor" href="#cuda核心组件"><span>CUDA核心组件</span></a></h5><ul><li><strong>CUDA驱动程序</strong>：提供GPU硬件的基础访问能力</li><li><strong>cuDNN</strong>：深度学习算子优化</li><li><strong>cuFFT</strong>：快速傅里叶变换</li><li><strong>cuBLAS</strong>：矩阵乘法、线性代数</li><li><strong>NVCC</strong>：编译器，把.cu文件编译成GPU可执行代码，<strong>要匹配GPU架构！！！</strong></li></ul>`,59)])])}const a=e(s,[["render",l]]),p=JSON.parse('{"path":"/dl/notes/Production.html","title":"Linux常见命令","lang":"zh-CN","frontmatter":{"title":"Linux常见命令","description":"记录一些常用linux命令和学到的知识","author":"xbZhong","isOriginal":true,"article":true,"category":"notes","timeline":true,"icon":"devicon:linux","date":"2025-08-26T00:00:00.000Z","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Linux常见命令\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-08-26T00:00:00.000Z\\",\\"dateModified\\":\\"2025-10-10T12:45:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"xbZhong\\"}]}"],["meta",{"property":"og:url","content":"https://xbzhong.cn/dl/notes/Production.html"}],["meta",{"property":"og:site_name","content":"牢钟的博客"}],["meta",{"property":"og:title","content":"Linux常见命令"}],["meta",{"property":"og:description","content":"记录一些常用linux命令和学到的知识"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-10-10T12:45:16.000Z"}],["meta",{"property":"article:author","content":"xbZhong"}],["meta",{"property":"article:published_time","content":"2025-08-26T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-10-10T12:45:16.000Z"}]]},"git":{"createdTime":1760100316000,"updatedTime":1760100316000,"contributors":[{"name":"BO","username":"BO","email":"2396768163@qq.com","commits":1,"url":"https://github.com/BO"}]},"readingTime":{"minutes":3.97,"words":1191},"filePathRelative":"dl/notes/Production.md","excerpt":"<p><strong>阿里云镜像</strong>：<code>-i https://mirrors.aliyun.com/pypi/simple/</code></p>\\n<p><code>nvidia-smi</code>：针对N卡，查看GPU型号，显存使用情况，使用率等</p>\\n<p><code>lscpu</code>：查看cpu的信息</p>\\n<ul>\\n<li><code>P-core</code>：性能核心（支持超线程，可以虚拟化为2个核心）</li>\\n<li><code>E-core</code>：能效核心（不支持超线程）</li>\\n</ul>\\n<p><code>lscpu | grep cache </code> ： 显示各级缓存大小</p>"}');export{a as comp,p as data};
